---
layout: post
title: 支持变长序列的Mamba-1训练
date: 2024-08-13 12:00:00
tags: Training System
categories: LLMs
redirect: https://zhuanlan.zhihu.com/p/714231501
---

## Abstract

Mamba 是一种专为处理长序列设计的新型架构，其相对于传统的 Transformer 架构能够显著提高超长序列文本的处理速度。在训练过程中，我们通常通过增加批次大小来提升训练效率。然而，实际应用中，数据序列长度往往分布不均，简单地通过填充（padding）来调整至固定长度可能会引入大量冗余数据，导致拖慢训练速度。为了解决这一问题，我们在 Mamba 框架中引入了一种新的序列处理机制。该机制能够打包（Pack）不同长度的序列，动态地识别和处理不同序列的上下文，避免上下文混淆，保证处理的一致性。这种方法能够减少冗余数据，显著提高训练速度。实验结果表明，在 NVIDIA A100 GPU 上使用 Mamba-1.4B 模型进行预训练时，与传统的单序列处理方案相比，加速比达到了 3.06 倍。这一改进不仅有效解决了变长序列处理的问题，还大幅提高了整体的训练和推理速度，使得模型在各种硬件上都能达到预期的训练效率。